{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM CRNN - OCR Model\n",
    "This model is desgined for recognition of handwritten names\n",
    "\n",
    "# Outline\n",
    "1. [Import Packages](#1)\n",
    "2. [Hyperparameters](#2)\n",
    "3. [Helper Functions](#3)\n",
    "4. [Model Architecture](#4)\n",
    "   - [Convolutional Layers (CNN)](#4.1)\n",
    "   - [Recurrent Layers (BiLSTM)](#4.2)\n",
    "   - [CTC Loss](#4.3)\n",
    "5. [Loading the Dataset](#5)\n",
    "6. [Building the Model](#6)\n",
    "   - [Defining CTC loss](#6.1)\n",
    "   - [Compiling the Model](#6.2)\n",
    "   - [Training](#6.3)\n",
    "7. [Evaluation and Predictions](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1 - Import Packages\n",
    "\n",
    "The following packages are used:\n",
    "- `numpy` for  scientific computation in python\n",
    "- `tensorflow` and `sklearn` for defining the model architecture\n",
    "- `os` and `pandas` for data manipulation\n",
    "- `cv2` for image manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-08-04T14:14:23.040626Z",
     "iopub.status.busy": "2021-08-04T14:14:23.040266Z",
     "iopub.status.idle": "2021-08-04T14:14:23.048334Z",
     "shell.execute_reply": "2021-08-04T14:14:23.047448Z",
     "shell.execute_reply.started": "2021-08-04T14:14:23.040594Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Reshape, \n",
    "                                     Bidirectional, LSTM, Dense, Lambda, Activation, \n",
    "                                     BatchNormalization, Dropout)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.backend import ctc_batch_cost, get_value, ctc_decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## 2 - Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:37:58.009397Z",
     "iopub.status.busy": "2021-08-04T12:37:58.009073Z",
     "iopub.status.idle": "2021-08-04T12:37:58.507038Z",
     "shell.execute_reply": "2021-08-04T12:37:58.506087Z",
     "shell.execute_reply.started": "2021-08-04T12:37:58.009369Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "IMAGE_HEIGHT = 64\n",
    "IMAGE_WIDTH = 256\n",
    "CHANNELS = 1  # Grayscale images\n",
    "SEQ_LENGTH = 64\n",
    "MAX_LABEL_LENGTH = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:38:10.504481Z",
     "iopub.status.busy": "2021-08-04T12:38:10.504125Z",
     "iopub.status.idle": "2021-08-04T12:38:10.614872Z",
     "shell.execute_reply": "2021-08-04T12:38:10.614145Z",
     "shell.execute_reply.started": "2021-08-04T12:38:10.504452Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ALPHABET = \"!\\\"#&'()*+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz \"\n",
    "CHAR_COUNT = len(ALPHABET) + 1  # Including CTC blank token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:38:16.329904Z",
     "iopub.status.busy": "2021-08-04T12:38:16.32956Z",
     "iopub.status.idle": "2021-08-04T12:38:16.404195Z",
     "shell.execute_reply": "2021-08-04T12:38:16.403314Z",
     "shell.execute_reply.started": "2021-08-04T12:38:16.329872Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "TRAIN_CSV_PATH = 'data/written_name_train.csv'\n",
    "VALID_CSV_PATH = 'data/written_name_valid.csv'\n",
    "TRAIN_IMAGE_PATH = 'data/train/train/'\n",
    "VALID_IMAGE_PATH = 'data/valid/valid/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "## 3 - Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:38:19.870035Z",
     "iopub.status.busy": "2021-08-04T12:38:19.869687Z",
     "iopub.status.idle": "2021-08-04T12:38:20.084768Z",
     "shell.execute_reply": "2021-08-04T12:38:20.083781Z",
     "shell.execute_reply.started": "2021-08-04T12:38:19.870002Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(csv_path, test_size=0.2):\n",
    "    \"\"\"Loads dataset, removes unreadable labels, and splits into train and validation sets.\"\"\"\n",
    "    df = pd.read_csv(csv_path).dropna()\n",
    "    df = df[df['IDENTITY'] != 'UNREADABLE']\n",
    "    df['IDENTITY'] = df['IDENTITY'].str.upper()  # Standardize labels\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:38:22.659466Z",
     "iopub.status.busy": "2021-08-04T12:38:22.659119Z",
     "iopub.status.idle": "2021-08-04T12:38:22.66587Z",
     "shell.execute_reply": "2021-08-04T12:38:22.663119Z",
     "shell.execute_reply.started": "2021-08-04T12:38:22.659435Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    \"\"\"Converts an image to a fixed size with normalization.\"\"\"\n",
    "    if img is None:\n",
    "        return None\n",
    "    final_img = np.ones((IMAGE_HEIGHT, IMAGE_WIDTH)) * 255  # White background\n",
    "    h, w = img.shape\n",
    "    final_img[:min(h, IMAGE_HEIGHT), :min(w, IMAGE_WIDTH)] = img[:IMAGE_HEIGHT, :IMAGE_WIDTH]\n",
    "    return cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE) / 255.0  # Rotate & Normalize\n",
    "\n",
    "def load_images(df, img_dir):\n",
    "    \"\"\"Loads and preprocesses images dynamically.\"\"\"\n",
    "    image_paths = df['FILENAME'].tolist()\n",
    "    images = []\n",
    "    \n",
    "    for img_name in image_paths:\n",
    "        img_path = os.path.join(img_dir, img_name)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            images.append(preprocess_image(img))\n",
    "    \n",
    "    return np.array(images).reshape(-1, IMAGE_WIDTH, IMAGE_HEIGHT, CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(df):\n",
    "    \"\"\"Converts text labels into numerical sequences.\"\"\"\n",
    "    num_samples = len(df)\n",
    "    label_sequences = np.ones((num_samples, MAX_LABEL_LENGTH)) * -1\n",
    "    label_lengths = np.zeros((num_samples, 1))\n",
    "    input_lengths = np.ones((num_samples, 1)) * (SEQ_LENGTH - 2)  # Adjusted for CTC loss\n",
    "\n",
    "    for i, text in enumerate(df['IDENTITY']):\n",
    "        label_lengths[i] = len(text)\n",
    "        label_sequences[i, :len(text)] = [ALPHABET.find(ch) for ch in text]\n",
    "\n",
    "    return label_sequences, label_lengths, input_lengths, np.zeros((num_samples,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "## 4 - Define a CRNN-BiLSTM model utilising CTC Loss\n",
    "Works best for OCR pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CRNN (Convolutional Recurrent Neural Network) combined with BiLSTM (Bidirectional Long Short-Term Memory) is a powerful architecture used for sequence-based tasks such as Optical Character Recognition (OCR), speech-to-text, and handwriting recognition.\n",
    "\n",
    "It consists of three main components:\n",
    "1.\tConvolutional Layers (CNN): Extract spatial features.\n",
    "\n",
    "2.\tRecurrent Layers (BiLSTM): Capture sequence dependencies.\n",
    "\n",
    "3.\tCTC Loss (Connectionist Temporal Classification): Handles unsegmented sequence labeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4.1\"></a>\n",
    "### 4.1 - Convolutional Layers (CNN)\n",
    "&emsp;The CNN module extracts spatial features from the input image. It applies multiple convolutional layers, followed by activation functions and pooling.\n",
    "\n",
    "&emsp;Operations:\n",
    "\n",
    "$$\n",
    "Z = W * X + B\n",
    "$$\n",
    "\n",
    "&emsp;where:\n",
    "- $X$ = input image(for feature map from previous layer)\n",
    "- $W$ = Convolution kernel (filter)\n",
    "- $B$ = Bias\n",
    "- $*$ = Convolution operation\n",
    "- $Z$ = Output feature map\n",
    "\n",
    "#### 4.1.2 Activation Function(ReLU):\n",
    "$$\n",
    "f(x) = max(0, x)\n",
    "$$\n",
    "\n",
    "#### 4.1.3 Max Pooling:\n",
    "$$\n",
    "P(i, j) = \\max \\{Z(i + m, j + n)\\}, \\quad \\forall m, n \\in K\n",
    "$$\n",
    "\n",
    "&emsp;where $K$ is the pooling window size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4.2\"></a>\n",
    "### 4.2 - Recurrent Layers (BiLSTM)\n",
    "&emsp;After extracting features using CNN, a Bidirectional LSTM (BiLSTM) processes the sequence in both forward and backward directions.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://www.researchgate.net/publication/373875187/figure/fig3/AS:11431281188406384@1694606838077/Structure-of-a-BiLSTM-cell-with-its-gates.jpg\" alt=\"BiLSTM Block\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "#### 4.2.1 LSTM Cell Equations:\n",
    "\n",
    "&emsp;$f_t = \\sigma(W_f x_t + U_f h_{t-1} + b_f)$\n",
    "\n",
    "\n",
    "&emsp;$i_t = \\sigma(W_i x_t + U_i h_{t-1} + b_i)$\n",
    "\n",
    "\n",
    "&emsp;$o_t = \\sigma(W_o x_t + U_o h_{t-1} + b_o)$\n",
    "\n",
    "\n",
    "&emsp;$c_t = f_t \\odot c_{t-1} + i_t \\odot \\tanh(W_c x_t + U_c h_{t-1} + b_c)$\n",
    "\n",
    "\n",
    "&emsp;$h_t = o_t \\odot \\tanh(c_t)$\n",
    "\n",
    "&emsp;where:\n",
    "- $f_t$ = Forget gate\n",
    "- $i_t$ = Input gate\n",
    "- $o_t$ = Output gate\n",
    "- $c_t$ = Cell state\n",
    "- $h_t$ = Hidden state\n",
    "- $\\sigma$ = Sigmoid function\n",
    "- $\\odot$ = Element-wise multiplication\n",
    "\n",
    "In BiLSTM, two LSTMs process the sequence in both directions, and the final output is:\n",
    "\n",
    "$\n",
    "h_t^{\\text{BiLSTM}} = h_t^{\\text{forward}} + h_t^{\\text{backward}}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:38:25.735049Z",
     "iopub.status.busy": "2021-08-04T12:38:25.73469Z",
     "iopub.status.idle": "2021-08-04T12:38:25.743007Z",
     "shell.execute_reply": "2021-08-04T12:38:25.741731Z",
     "shell.execute_reply.started": "2021-08-04T12:38:25.735017Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_ocr_model(seq_length, char_count):\n",
    "    input_tensor = Input(shape=(256, 64, 1), name='input')\n",
    "    features = Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal')(input_tensor)\n",
    "    features = BatchNormalization()(features)\n",
    "    features = Activation('relu')(features)\n",
    "    features = MaxPooling2D(pool_size=(2, 2))(features)\n",
    "    \n",
    "    features = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal')(features)\n",
    "    features = BatchNormalization()(features)\n",
    "    features = Activation('relu')(features)\n",
    "    features = MaxPooling2D(pool_size=(2, 2))(features)\n",
    "    features = Dropout(0.3)(features)\n",
    "    \n",
    "    features = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal')(features)\n",
    "    features = BatchNormalization()(features)\n",
    "    features = Activation('relu')(features)\n",
    "    features = MaxPooling2D(pool_size=(1, 2))(features)\n",
    "    features = Dropout(0.3)(features)\n",
    "    \n",
    "    features = Reshape(target_shape=(seq_length, 1024))(features)\n",
    "    features = Dense(64, activation='relu', kernel_initializer='he_normal')(features)\n",
    "    features = Bidirectional(LSTM(256, return_sequences=True))(features)\n",
    "    features = Bidirectional(LSTM(256, return_sequences=True))(features)\n",
    "    features = Dense(char_count, kernel_initializer='he_normal')(features)\n",
    "    preds = Activation('softmax', name='softmax')(features)\n",
    "    \n",
    "    return Model(inputs=input_tensor, outputs=preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4.3\"></a>\n",
    "### 4.3 - CTC Loss (Connectionist Temporal Classification)\n",
    "&emsp;CTC loss is used when the input and output sequences do not have a strict alignment (e.g., OCR tasks where the number of characters varies).\n",
    "\n",
    "#### 4.3.1 Probability of Alignment Path:\n",
    "$\n",
    "P(y|X) = \\sum_{\\pi \\in \\mathcal{A}(y)} P(\\pi | X)\n",
    "$\n",
    "\n",
    "&emsp;where:\n",
    "- $X$ = Input sequence\n",
    "- $y$ = Target sequence\n",
    "- $\\pi$ = Possible alignments\n",
    "- $\\mathcal{A}(y)$ = Set of all valid alignments\n",
    "\n",
    "#### 4.3.2 CTC Loss Function\n",
    "$\n",
    "\\mathcal{L}{CTC} = - \\sum{t=1}^{T} \\log P(y_t | X)\n",
    "$\n",
    "\n",
    "CTC allows the model to learn character sequences without explicit alignment between input images and text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:38:28.539537Z",
     "iopub.status.busy": "2021-08-04T12:38:28.53919Z",
     "iopub.status.idle": "2021-08-04T12:38:28.544068Z",
     "shell.execute_reply": "2021-08-04T12:38:28.543159Z",
     "shell.execute_reply.started": "2021-08-04T12:38:28.539506Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def ctc_loss_layer(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    return ctc_batch_cost(labels, y_pred[:, 2:, :], input_length, label_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"5\"></a>\n",
    "## 5 - Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:38:30.850798Z",
     "iopub.status.busy": "2021-08-04T12:38:30.850486Z",
     "iopub.status.idle": "2021-08-04T12:41:47.665446Z",
     "shell.execute_reply": "2021-08-04T12:41:47.664648Z",
     "shell.execute_reply.started": "2021-08-04T12:38:30.850768Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data = load_dataset(TRAIN_CSV_PATH)\n",
    "valid_data = load_dataset(VALID_CSV_PATH)\n",
    "\n",
    "# Load images\n",
    "train_images = load_images(train_data, TRAIN_IMAGE_PATH)\n",
    "valid_images = load_images(valid_data, VALID_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:42:13.936512Z",
     "iopub.status.busy": "2021-08-04T12:42:13.936194Z",
     "iopub.status.idle": "2021-08-04T12:42:15.255252Z",
     "shell.execute_reply": "2021-08-04T12:42:15.254198Z",
     "shell.execute_reply.started": "2021-08-04T12:42:13.936481Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "train_labels, train_label_len, train_input_len, train_output = encode_labels(train_data)\n",
    "valid_labels, valid_label_len, valid_input_len, valid_output = encode_labels(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train Samples: {len(train_data)}, Validation Samples: {len(valid_data)}\")\n",
    "print(f\"Image Shape: {train_images.shape}, Label Shape: {train_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"6\"></a>\n",
    "## 6 - Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:42:24.406578Z",
     "iopub.status.busy": "2021-08-04T12:42:24.406255Z",
     "iopub.status.idle": "2021-08-04T12:42:25.812961Z",
     "shell.execute_reply": "2021-08-04T12:42:25.811596Z",
     "shell.execute_reply.started": "2021-08-04T12:42:24.40655Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Build OCR model\n",
    "pre_model = build_ocr_model(SEQ_LENGTH, CHAR_COUNT)\n",
    "pre_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"6.1\"></a>\n",
    "### 6.1 - Defining CTC loss model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:42:28.316409Z",
     "iopub.status.busy": "2021-08-04T12:42:28.316078Z",
     "iopub.status.idle": "2021-08-04T12:42:28.47107Z",
     "shell.execute_reply": "2021-08-04T12:42:28.470319Z",
     "shell.execute_reply.started": "2021-08-04T12:42:28.316379Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ground_truth_labels = Input(name='gtruth_labels', shape=[MAX_LABEL_LENGTH], dtype='float32')\n",
    "input_lengths = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_lengths = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "ctc_loss = Lambda(ctc_loss_layer, output_shape=(1,), name='ctc')(\n",
    "    [pre_model.output, ground_truth_labels, input_lengths, label_lengths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_model = Model(inputs=[pre_model.input, ground_truth_labels, input_lengths, label_lengths], \n",
    "                       outputs=ctc_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"6.2\"></a>\n",
    "### 6.2 - Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:42:35.036673Z",
     "iopub.status.busy": "2021-08-04T12:42:35.036344Z",
     "iopub.status.idle": "2021-08-04T12:42:38.011934Z",
     "shell.execute_reply": "2021-08-04T12:42:38.011075Z",
     "shell.execute_reply.started": "2021-08-04T12:42:35.036644Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "best_model_file = \"Best_OCR_Model.keras\"\n",
    "ocr_model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(0.0001))\n",
    "checkpoint = ModelCheckpoint(filepath=best_model_file, monitor='val_loss', save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"6.3\"></a>\n",
    "### 6.3 - Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:42:58.506885Z",
     "iopub.status.busy": "2021-08-04T12:42:58.506564Z",
     "iopub.status.idle": "2021-08-04T12:42:58.512259Z",
     "shell.execute_reply": "2021-08-04T12:42:58.511169Z",
     "shell.execute_reply.started": "2021-08-04T12:42:58.506856Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history = ocr_model.fit(\n",
    "    x=[train_images, train_labels, train_input_len, train_label_len],\n",
    "    y=train_output,\n",
    "    validation_data=([valid_images, valid_labels, valid_input_len, valid_label_len], valid_output),\n",
    "    epochs=60, \n",
    "    batch_size=128, \n",
    "    shuffle=True,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the loss graph of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T13:28:28.128626Z",
     "iopub.status.busy": "2021-08-04T13:28:28.128257Z",
     "iopub.status.idle": "2021-08-04T13:28:28.283037Z",
     "shell.execute_reply": "2021-08-04T13:28:28.282Z",
     "shell.execute_reply.started": "2021-08-04T13:28:28.128592Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"7\"></a>\n",
    "### 7 - Evaluation and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T13:29:14.157928Z",
     "iopub.status.busy": "2021-08-04T13:29:14.157606Z",
     "iopub.status.idle": "2021-08-04T13:29:14.200171Z",
     "shell.execute_reply": "2021-08-04T13:29:14.199434Z",
     "shell.execute_reply.started": "2021-08-04T13:29:14.157899Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ocr_model.load_weights('Best_OCR_Model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_label(num_seq, alphabet):\n",
    "    text = []\n",
    "    for num in num_seq:\n",
    "        if num != -1:\n",
    "            text.append(alphabet[num])\n",
    "    return ''.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to test images\n",
    "test_dir = 'data/test/test/'\n",
    "\n",
    "# Get list of test images\n",
    "test_images = sorted(os.listdir(test_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store predictions\n",
    "submission_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter\n",
    "total_images = len(test_images)\n",
    "print(f\"Total images to process: {total_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Prediction on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for test images\n",
    "for idx, img_name in enumerate(test_images, start=1):\n",
    "    img_path = os.path.join(test_dir, img_name)\n",
    "    image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if image is not None:\n",
    "        image = preprocess_image(image)  # Preprocess the image\n",
    "        pred = pre_model.predict(image.reshape(1, 256, 64, 1), verbose=False)\n",
    "        decoded = get_value(ctc_decode(pred, input_length=np.ones(pred.shape[0]) * pred.shape[1], greedy=True)[0][0])\n",
    "        pred_text = num_to_label(decoded[0], ALPHABET)\n",
    "    else:\n",
    "        pred_text = \"MISSING_LABEL\"  # If the image is missing, leave an missing prediction\n",
    "\n",
    "    submission_data.append([img_name, pred_text])\n",
    "\n",
    "    # Show progress\n",
    "    print(f\"Processed {idx}/{total_images} images\", end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame and save as CSV\n",
    "submission_df = pd.DataFrame(submission_data, columns=['Id', 'Predicted'])\n",
    "submission_df.to_csv('written_test.csv', index=False)\n",
    "\n",
    "print(\"Submission file 'written_test.csv' has been created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load submission CSV\n",
    "submission_df = pd.read_csv(\"written_test.csv\")\n",
    "\n",
    "# Test image directory\n",
    "test_dir = \"data/test/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_prediction(image_index):\n",
    "    \"\"\" Function to display image and its predicted label. \"\"\"\n",
    "    \n",
    "    # Get the image filename and predicted label from submission file\n",
    "    img_name = submission_df.loc[image_index, 'Id']\n",
    "    predicted_label = submission_df.loc[image_index, 'Predicted']\n",
    "    img_path = os.path.join(test_dir, img_name)\n",
    "\n",
    "    # Load and preprocess image\n",
    "    image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        print(f\"Error loading image: {img_name}\")\n",
    "        return\n",
    "    \n",
    "    processed_image = preprocess_image(image)\n",
    "\n",
    "    # Model prediction\n",
    "    pred = pre_model.predict(processed_image.reshape(1, 256, 64, 1))\n",
    "    decoded = get_value(ctc_decode(pred, input_length=np.ones(pred.shape[0]) * pred.shape[1], greedy=True)[0][0])\n",
    "    model_predicted_text = num_to_label(decoded[0], ALPHABET)\n",
    "\n",
    "    # Display image\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Submission Prediction: {predicted_label}\", fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually load image and prediction for error checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    img_idx = int(input(f\"Enter an image index (0 to {len(submission_df)-1}), or -1 to exit: \"))\n",
    "    if 0 <= img_idx < len(submission_df):\n",
    "        display_prediction(img_idx)\n",
    "    else:\n",
    "        print(\"Invalid index. Please enter a valid number\")\n",
    "except ValueError:\n",
    "    print(\"Please enter a valid integer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
